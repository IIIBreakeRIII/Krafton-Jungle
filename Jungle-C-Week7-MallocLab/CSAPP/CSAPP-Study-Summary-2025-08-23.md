# CS:APP 스터디 요약 (Virtual Memory 중심) — 2025-08-23
**총 학습 시간:** 1:11:19 (약 71.3분)  
**요약 분량 기준:** 10분당 2,000자 ⇒ **최소 14265자** 이상

---

## 1) 가상 메모리(Virtual Memory)의 목적과 큰 그림
- **핵심 역할(3가지)**: (1) 디스크 상의 거대한 **가상 주소 공간**을 DRAM으로 **캐시**처럼 운용, (2) 모든 프로세스에 **균일하고 단순한 주소 공간**을 제공하여 메모리 관리를 단순화, (3) 프로세스 간 **메모리 보호** 제공.  
- **문제 배경**: 여러 프로세스가 메인 메모리를 공유하면 **공간 부족**이나 **상호 침범**으로 오동작이 발생할 수 있음. VM은 이런 위험을 완화하며, 각 프로세스에 **사적(Private) 주소 공간**을 주는 추상화를 제공.
- **주소 공간의 개념**: 비음수 정수의 연속 집합으로 정의되는 주소; **가상 주소(virtual address)**와 **물리 주소(physical address)**를 구분. CPU는 가상 주소를 생성하고, **MMU**(Memory Management Unit)가 이를 물리 주소로 **주소 변환**(translation)한다.

## 2) DRAM을 ‘디스크의 캐시’로 쓰기: 페이지 단위 모델
- 디스크의 가상 주소 공간을 **가상 페이지(Virtual Page, VP)**로, DRAM을 **물리 페이지(Physical Page, PP)**로 나눠 **캐싱 계층**처럼 운용.  
- VP의 상태: **Unallocated(미할당)** / **Cached(할당+DRAM 상주)** / **Uncached(할당+디스크 상주)**.  
- **페이지 적중/부재**: DRAM에 해당 VP가 있으면 **페이지 히트**, 없으면 **페이지 폴트**. 폴트 시 운영체제는 **희생 페이지**를 고르고, 필요한 페이지를 디스크에서 DRAM으로 **페이지 인(page-in)**, 내보낼 때는 **페이지 아웃(page-out)** 수행.
- **쓰기 정책**: DRAM 계층은 **write-back**이 일반적. 캐시 라인이 바뀌면 **더티 비트(dirty bit)**로 표시해 두었다가 교체 시 디스크에 반영. **write-through**는 디스크 접근 비용이 너무 커서 비현실적.
- **교체 알고리즘**: DRAM 미스 비용이 크므로 하드웨어 캐시보다 **더 정교한 알고리즘**(OS 레벨) 사용.

## 3) SRAM과 DRAM, 디스크의 속도·위치 감각
- **SRAM(L1/L2/L3 캐시)**는 DRAM보다 **최소 수십 배** 빠르고, **디스크는 DRAM보다 약 10⁵배 느림**에 가깝다.  
- 따라서 **DRAM 미스**는 **SRAM 미스**보다 훨씬 **비싸다**. 첫 바이트 접근이 특히 느리지만, **연속 바이트**는 상대적으로 빠르다는 특성도 짚음.  
- 실제 시스템에서는 DDR3/DDR4 같은 **DDR-DRAM**이 주로 쓰이며, CPU 패키지 내부의 **SRAM 캐시 용량**(예: 16MB 스마트 캐시)이 제한적임을 확인.

## 4) 페이지 테이블(Page Table)과 PTE
- **페이지 테이블 엔트리(PTE)**는 각 VP의 상태와 매핑 정보를 기록.  
  - **Valid 비트**: 1이면 DRAM에 상주 중이며 **PP 번호(PPN)**를 보유. 0인데 주소가 있으면 **디스크 위치**를 가리킴, 0이고 null이면 **미할당**.  
  - **권한 비트**: **읽기/쓰기/실행** 권한 및 **슈퍼바이저(커널) 모드 요구** 여부 등 접근 제어.
- 예시 흐름: CPU가 **VP2**에 접근 → MMU가 **PTE[2]** 확인 → valid=1이면 해당 **PPN**과 **오프셋**으로 **물리 주소** 형성 → 메모리 접근.  
- **페이지 폴트** 예시: **VP3** 접근 시 valid=0이고 디스크에 있음 → OS가 **희생 페이지**(예: PP에 있던 VP4)를 교체, 더티면 먼저 쓰기 반영 → VP3를 **page-in** → PTE 갱신 → 예외 복귀 후 재실행 시 히트.

## 5) 요구 페이징(Delayed/Demand Paging)과 지역성(Locality)
- 현대 OS는 **요구 페이징**을 기본으로 함: **실제로 필요할 때**만 페이지를 적재. 사전 적재는 제한적으로만 사용.  
- 프로그램은 실행 중 대부분의 시간을 **작은 활성 페이지 집합(워킹셋)**에 머문다(지역성).  
- 워킹셋 크기가 물리 메모리를 넘으면 **스래싱(thrashing)**: page-in/out이 과도하게 발생하여 성능 급락. 개발자는 **지역성 친화적** 코드/데이터 배치를 통해 이를 예방할 필요.

## 6) 접근 제어와 예외
- 사용자 프로세스는 (1) 자신의 **읽기 전용 코드**를 수정하거나, (2) **커널** 데이터/코드를 읽거나 쓰거나, (3) **다른 프로세스**의 메모리에 접근하면 안 됨.  
- **페이지 단위 접근 제어**: PTE의 권한 비트로 통제. **슈퍼바이저 모드 요구** 비트가 설정된 페이지는 커널 모드에서만 접근 가능.  
- 위반 시 CPU가 **일반 보호 예외**(Linux에선 흔히 **Segmentation Fault**)를 일으키고, 커널 예외 핸들러가 해당 프로세스에 시그널을 전달.

## 7) 주소 번역의 기계적 절차(단일 레벨 관점)
- 가상 주소는 **VPN(가상 페이지 번호)** + **VPO(페이지 오프셋)**로 나뉨. 물리 주소는 **PPN** + **PPO**로 표현되고 **VPO==PPO**(동일 오프셋).  
- **PTBR(예: x86 CR3)**는 현재 활성 페이지 테이블의 **시작 주소**.  
- 변환 절차(히트 경로):  
  1) CPU가 VA 생성 → MMU로 전달.  
  2) **PTEA**(PTE의 메모리 주소) 계산: PTBR + (VPN × PTE 크기).  
  3) DRAM에서 PTE 로드 → valid=1이면 PPN 획득.  
  4) **물리 주소 = PPN‖VPO** 형성 후 데이터 접근.  
- **미스 경로(페이지 폴트)**: PTE가 유효하지 않으면 예외 발생 → 커널이 **교체·적재** 후 PTE 갱신 → **재시작**.

## 8) TLB(Translation Lookaside Buffer)
- PTE를 DRAM에서 매번 찾는 오버헤드를 줄이기 위한 **소규모, 고속 캐시**.  
- **태그/인덱스**를 이용해 VPN 일부로 조회. **TLB 히트**면 즉시 PPN 획득, **TLB 미스**면 페이지 테이블을 참조해 TLB를 갱신.  
- 캐시 설계 관점에서 L1은 보통 **VIPT**(Virtual-Indexed, Physical-Tagged), L2/L3는 **PIPT**(Physically Indexed/Tagged)에 가까운 구성이라는 논의도 등장.

## 9) 다중 레벨 페이지 테이블(32비트 예)
- 32비트 VA, **4KB 페이지**, **PTE=4B** 예시: 단일 테이블은 **2²⁰개 PTE(≈1M)**가 필요해 **비효율적**.  
- 해결: **2레벨 PT**로 분해. **레벨1**은 포인터들만 보유(**널인 엔트리는 미할당**)하고, 실제 **PTE 배열은 레벨2**에 존재. **사용되는 하위 테이블만** 메모리에 두어 공간·탐색을 최적화.  
- 결과적으로 **주소 비트**는 `VPN1 | VPN2 | VPO`로 쪼개지고, 필요할 때만 하위 테이블을 생성·상주시킴.

## 10) x86-64(i7) 주소 번역 개요
- 한 구현 예로 **48비트 가상 주소**, **52비트 물리 주소**(레퍼런스 기준). **4KB 페이지**에서는 **가상= 9-9-9-9-12 분할**로 **4레벨** 탐색(PML4→PDPT→PD→PT).  
- 상위 36비트(VPN)는 TLB의 **태그/인덱스**로 사용되며, 히트 시 곧바로 PPN 결정을 돕고 미스 시 다중 레벨 테이블을 순차 탐색.  
- **CR3 레지스터**가 현재 프로세스의 최상위 테이블(PGD/PML4)을 가리킨다. 컨텍스트 스위치 때 **CR3 교체**로 주소 공간 전환.

## 11) 리눅스의 가상 메모리 영역과 자료구조
- 한 프로세스의 주소 공간은 **텍스트/데이터/힙/스택**뿐만 아니라, **커널 매핑**, **페이지 테이블**, **물리 메모리 맵** 등도 상단 영역에 고정적으로 배치.  
- 커널이 관리하는 `mm_struct`는 최상위 페이지 디렉터리(PGD)와 함께, 각 영역을 나타내는 **VMA(가상 메모리 영역)** 목록(`vm_area_struct`)을 보유: `vm_start`, `vm_end`, 권한, 공유 여부, 다음 포인터 등.  
- 실행 중 활성 프로세스의 **PGD 시작 주소는 CR3**에 적재되어 주소 번역의 기준이 된다.

## 12) 예외 처리의 세 가지 대표 상황
1. **잘못된 주소(세그폴트)**: 접근 VA가 어떤 VMA의 `[start, end)`에도 포함되지 않거나, 권한 위반(예: read-only에 write)일 때.  
2. **페이지 폴트(정상적 상황)**: 파일·익명 페이지가 필요하지만 아직 메모리에 없음 → **demand paging**으로 적재.  
3. **교체 필요**: DRAM 가용 PP가 없으면 **희생 페이지** 선정 → 더티면 쓰기 반영 → 새 VP 적재.

## 13) 메모리 맵핑(mmap)과 파일·익명 매핑
- **파일 매핑(file-backed)**: 실행 파일 텍스트/데이터, 공유 라이브러리 등 **실제 파일**과 매핑. 필요 시 해당 파일에서 page-in.  
- **익명 매핑(anonymous)**: 파일이 아닌 **제로 페이지** 기반(초기값 0). 전역/정적의 **BSS**, 동적 할당 영역 일부가 해당. 실제 데이터는 접근 순간에 만들어지며, 메모리-디스크 간 **실제 데이터 이동이 없을 수도 있음**(초기에 ‘무효/제로’ 페이지 참조).

## 14) 공유 매핑과 Copy-on-Write(COW)
- 서로 다른 프로세스가 **같은 물리 페이지**를 **공유**할 수 있음(읽기 위주).  
- 누군가 **쓰기**를 시도하면 **보호 예외**를 일으켜 커널이 **새 물리 페이지를 할당**하고, 원본을 **복사**해 씀(**COW**). 이후 각 프로세스는 **독립 복사본**을 사용하여 간섭 없이 진행.  
- `fork()` 후 `execve()` 이전의 **주소 공간 복제 비용 최소화**에도 COW가 핵심적으로 활용됨.

---

## 15) 발표 중 나온 주요 Q&A/예시 정리
- **Write-back vs Write-through**: write-back은 **지연 기록**으로 디스크 I/O를 줄이고, **더티 비트**로 변경 여부만 추적. 교체 시 한 번만 기록.  
- **PTE 값 해석**: `valid=1` → DRAM 상주/PPN 보유, `valid=0 & addr=null` → 미할당, `valid=0 & addr≠null` → 디스크 위치 보유.  
- **VP2/VP3 예**: VP2는 히트 경로로 바로 접근. VP3는 폴트 처리(희생=VP4) 후 재시작 시 히트.  
- **Demand paging**: “처음부터 미리 넣지 말고 **요청 시** 적재”로 요약.  
- **TLB 설계**: L1은 **VIPT** 경향, L2/L3는 **PIPT** 경향을 소개.  
- **스레싱 주의**: 워킹셋이 물리 메모리를 초과하면 성능이 급락하므로 **지역성**을 고려해 데이터 구조·접근 패턴을 설계.

## 16) 개념 간 연결(두 캐시 계층의 대비)
- **가상 메모리 시스템**: **디스크↔DRAM** 사이에서 **커널(OS)**이 관리(페이지 폴트, 교체, 정책).  
- **CPU 캐시 시스템**: **DRAM↔SRAM(L1/L2/L3)** 사이에서 **하드웨어**가 관리(TLB/캐시 미스, 교체 정책).  
- 용어는 다르나 **‘상하위 계층 간에 일부만 올려놓고 쓴다’**는 캐싱 철학은 동일.

---

## 17) 용어 메모
- **VP/PP**: Virtual/Physical Page  
- **VPN/VPO, PPN/PPO**: Page Number/Offset 분해  
- **PT/PTE, PTBR(CR3)**: 페이지 테이블/엔트리, 최상위 테이블 기준 레지스터  
- **TLB**: 주소 변환 캐시  
- **Dirty/Referenced bit**: 쓰기 발생/참조 흔적 추적(교체 정책에 활용)  
- **mmap**: 파일/익명 매핑, COW: 쓰기 시 복사

---

## 18) 스터디 토론 포인트(발표 메모)
- L1/L2/L3 분할 이유, L3의 **코어 간 공유** 의미.  
- **DMA/인터커넥트**(예: QPI/UPI 등)로 메모리 컨트롤러 우회 시 **레이턴시 단축**.  
- 48비트 VA의 **상위 비트 분할(9-9-9-9-12)**과 TLB의 역할 분담.  
- 리눅스 `mm_struct`/`vm_area_struct`로 **VMA 리스트** 추적, `CR3←PGD` 로딩과 컨텍스트 스위칭.

---

### 결론
이 세션은 가상 메모리의 **추상화·보호·성능** 측면을 **페이지 단위 캐싱 모델**로 연결해 해설했고, **주소 변환의 실제 절차**(PTE/TLB/다중 레벨 PT, CR3)와 **리눅스의 영역/예외/매핑/COW**까지 한 흐름으로 정리했다. 결과적으로 VM은 **안전한 프로세스 격리**와 **효율적인 메모리 이용**을 동시에 달성하는 핵심 메커니즘임을 확인했다.

---

## 부록 A) 예시를 통한 주소 번역 빠른 복기
- **PTEA 계산**: `PTEA = PTBR + VPN × sizeof(PTE)`  
- **히트 케이스**: `valid=1` → `PPN‖VPO`로 물리주소 형성 → 메모리 접근.  
- **폴트 케이스**: `valid=0` → 예외 진입 → (더티면) **페이지 아웃** → **페이지 인** → PTE 갱신 → 재시작.

## 부록 B) 쓰기 정책과 더티/레퍼런스 비트
- **Write-back**: 변경이 누적되다 교체 시 한 번 기록. 더티 비트가 1이면 디스크/파일로 반영.  
- **Referenced(Accessed) 비트**: 교체 후보 선정에 사용(최근 참조 흔적).

## 부록 C) 2레벨 PT에서의 메모리 절약 직관
- 레벨1의 포인터 엔트리 중 **널(null)**인 것은 **하위 테이블 자체를 만들지 않음** → 사용 영역만 실제 PTE 배열을 보유.  
- **연속적이지 않은 주소 사용**에 특히 유리.

## 부록 D) COW 동작 스냅샷
1) 프로세스 A와 B가 동일 물리 페이지(읽기 전용) 공유.  
2) B가 쓰기 시도 → 보호 예외 → 커널이 **새 PP 할당** 후 원본을 복사.  
3) 이후 A는 원본, B는 사본을 가리키며 **독립적 갱신**.

## 부록 E) 성능 관점 체크리스트
- **지역성**(시간/공간)을 해치지 않는 접근 패턴 설계.  
- 큰 구조체/배열 순차 접근, 자주 쓰는 데이터는 **근접 배치**.  
- 불필요한 페이지 교체를 유발하는 **랜덤 접근** 최소화.


- 핵심 요지 복기: 가상 메모리는 디스크↔DRAM을 페이지 단위로 캐싱하고, CPU 캐시는 DRAM↔SRAM을 블록 단위로 캐싱한다.
- 주소 변환은 PTE/TLB/다중 레벨 페이지 테이블을 통해 이루어지며, CR3가 최상위 테이블을 지정한다.
- 접근 제어는 PTE의 권한 비트로 강제되고, 위반 시 예외(세그폴트)가 발생한다.
- 요구 페이징과 지역성은 성능을 좌우하며, 스레싱 방지를 위해 워킹셋 관리가 중요하다.